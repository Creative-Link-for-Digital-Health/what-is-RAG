{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51adc40",
   "metadata": {},
   "source": [
    "# Putting all of the Pieces Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ba1b8",
   "metadata": {},
   "source": [
    "Now that we know how to evaluate semantic similarity using a database, we can proceed to an actual RAG implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install chromadb\n",
    "! pip install ollama\n",
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85a68c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import uuid\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "from openai import OpenAI\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "from api_utils import load_api_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e6a211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dmitrystrakovsky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the punkt tokenizer models that will help us split our text into sentences.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86f60e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./heart_attack.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2b39ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 108\n",
      "Did the Jabberwock talk to the Vorpal Blade?\n"
     ]
    }
   ],
   "source": [
    "# Break our story up into seperate sentances\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "sentences = tokenizer.tokenize(text)\n",
    "\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "print(sentences[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272e63a",
   "metadata": {},
   "source": [
    "## Now that our sentences are split, we can generate embeddings for individual sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdc9b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Nomic model served locally via Ollama for embedding\n",
    "# Ollama is a friend --> https://ollama.com/\n",
    "def get_embeddings_from_ollama(text, model=\"nomic-embed-text\"):\n",
    "    url = \"http://localhost:11434/api/embeddings\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": text\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=payload)\n",
    "    return np.array(response.json()[\"embedding\"], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "212888d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for sentence in sentences:\n",
    "    embedding = get_embeddings_from_ollama(sentence)\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73cc78",
   "metadata": {},
   "source": [
    "## And now, on to packing everything into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a54e65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac4aa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique collection and add the embeddings to it\n",
    "\n",
    "unique_collection_name = f\"document_sentences_{int(time.time())}\"\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=unique_collection_name,\n",
    "    metadata={\"hnsw:space\": \"cosine\"}  # Using cosine similarity\n",
    ")\n",
    "\n",
    "# Generate IDs for each sentence\n",
    "ids = [str(uuid.uuid4()) for _ in embeddings]\n",
    "\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings,\n",
    "    documents=sentences\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95935a",
   "metadata": {},
   "source": [
    "## And now ... bringing in the LLM and the full RAG experience with semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4053671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API parameters and initialize client\n",
    "\n",
    "SECRETS_PATH = \".secrets.toml\"\n",
    "\n",
    "API_CALL_PARAMS = load_api_params(SECRETS_PATH)\n",
    "client = OpenAI(\n",
    "    base_url = API_CALL_PARAMS['API_URL'],\n",
    "    api_key = API_CALL_PARAMS['API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6536c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(model: str, messages: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"Generate LLM output\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "290a706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"Can you please tell me what is a heart attack.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c68c31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = get_embeddings_from_ollama(USER_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "724aed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36e966d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query results for: Can you please tell me what is a heart attack.\n",
      "Result 1: \"This is a Heart Attack!\n",
      "Result 2: And here, a Heart Attack means war.\"\n",
      "Result 3: \"I thought a heart attack was a medical condition,\" Alice replied, confused.\n",
      "Result 4: We shall launch a Heart Attack immediately!\"\n",
      "Result 5: We will show her why they fear a Heart Attack above all else!\"\n",
      "Result 6: \"It's always tea time during a Heart Attack!\n",
      "Result 7: # Heart Attack: A Wonderland Tale\n",
      "\n",
      "\"Off with her head!\"\n",
      "Result 8: ATTACK!\"\n",
      "Result 9: \"That's what they call it when the Heart kingdom launches an offensive.\"\n",
      "Result 10: \"Well,\" huffed the Queen of Hearts, \"I suppose we could postpone the Heart Attack.\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[query_vector],\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "print(\"Query results for:\", USER_PROMPT)\n",
    "for i, (doc, distance) in enumerate(zip(results[\"documents\"][0], results[\"distances\"][0])):\n",
    "    print(f\"Result {i+1}: {doc}\")\n",
    "    KNOWLEDGE += str(doc)+\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f12ed3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer all user questions to the best of your ability. Use the following text for reference:\n",
      "\n",
      "\"This is a Heart Attack!\n",
      "And here, a Heart Attack means war.\"\n",
      "\"I thought a heart attack was a medical condition,\" Alice replied, confused.\n",
      "We shall launch a Heart Attack immediately!\"\n",
      "We will show her why they fear a Heart Attack above all else!\"\n",
      "\"It's always tea time during a Heart Attack!\n",
      "# Heart Attack: A Wonderland Tale\n",
      "\n",
      "\"Off with her head!\"\n",
      "ATTACK!\"\n",
      "\"That's what they call it when the Heart kingdom launches an offensive.\"\n",
      "\"Well,\" huffed the Queen of Hearts, \"I suppose we could postpone the Heart Attack.\n",
      "\"This is a Heart Attack!\n",
      "And here, a Heart Attack means war.\"\n",
      "\"I thought a heart attack was a medical condition,\" Alice replied, confused.\n",
      "We shall launch a Heart Attack immediately!\"\n",
      "We will show her why they fear a Heart Attack above all else!\"\n",
      "\"This is a Heart Attack!\n",
      "And here, a Heart Attack means war.\"\n",
      "\"I thought a heart attack was a medical condition,\" Alice replied, confused.\n",
      "We shall launch a Heart Attack immediately!\"\n",
      "We will show her why they fear a Heart Attack above all else!\"\n",
      "\"It's always tea time during a Heart Attack!\n",
      "# Heart Attack: A Wonderland Tale\n",
      "\n",
      "\"Off with her head!\"\n",
      "ATTACK!\"\n",
      "\"That's what they call it when the Heart kingdom launches an offensive.\"\n",
      "\"Well,\" huffed the Queen of Hearts, \"I suppose we could postpone the Heart Attack.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"Answer all user questions to the best of your ability. Use the following text for reference:\n",
    "\n",
    "{KNOWLEDGE}\n",
    "\"\"\"\n",
    "\n",
    "print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1aaa2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of the provided text, a \"Heart Attack\" refers to a war or an offensive launched by the Heart kingdom, not a medical condition. It's a term used by the Queen of Hearts and her kingdom to describe a military attack.\n",
      "\n",
      "In the real world, however, a heart attack (also known as a myocardial infarction) is a serious medical condition that occurs when the blood flow to the heart is blocked, causing damage to the heart muscle. But in this Wonderland tale, it has a very different meaning!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"{SYSTEM_PROMPT}\"\"\"},\n",
    "    {\"role\": \"user\", \"content\":f\"\"\"{USER_PROMPT}\"\"\"}\n",
    "]\n",
    "try:\n",
    "    model = API_CALL_PARAMS['MODEL']\n",
    "    LLM_output = generate_completion(model, messages)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error generating completion: {e}\")\n",
    "\n",
    "print(LLM_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-presentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
