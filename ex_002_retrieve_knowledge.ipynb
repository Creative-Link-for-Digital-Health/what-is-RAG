{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Knowledge from an External File\n",
    "\n",
    "When we manually add external text to the system prompt, we are performing the retrieval step and augmenting the context that LLM receives. This gives LLM access to specific information that may not be in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "\n",
    "from openai import OpenAI\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "from api_utils import load_api_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API parameters and initialize client\n",
    "\n",
    "SECRETS_PATH = \".secrets.toml\"\n",
    "\n",
    "API_CALL_PARAMS = load_api_params(SECRETS_PATH)\n",
    "client = OpenAI(\n",
    "    base_url = API_CALL_PARAMS['API_URL'],\n",
    "    api_key = API_CALL_PARAMS['API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(model: str, messages: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"Generate LLM output\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def load_story_from_file(filename):\n",
    "    \"\"\"Load story text from a file\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE = load_story_from_file('heart_attack.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"Answer all user questions to the best of your ability. Use the following text for reference:\n",
    "\n",
    "{KNOWLEDGE}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"Can you please tell me what is a heart attack.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of the story \"Heart Attack: A Wonderland Tale\", a Heart Attack refers to a war or an attack launched by the Queen of Hearts and her kingdom against the Queen of Spades and her kingdom.\n",
      "\n",
      "However, in the real world, a heart attack (also known as myocardial infarction) is a serious medical condition that occurs when the blood flow to the heart is blocked, causing damage to the heart muscle. It's a life-threatening condition that requires immediate medical attention.\n",
      "\n",
      "In the story, Alice initially misunderstands the term \"Heart Attack\" and thinks it's a medical condition, and the Duchess clarifies that in Wonderland, it means war.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"{SYSTEM_PROMPT}\"\"\"},\n",
    "    {\"role\": \"user\", \"content\":f\"\"\"{USER_PROMPT}\"\"\"}\n",
    "]\n",
    "try:\n",
    "    model = API_CALL_PARAMS['MODEL']\n",
    "    LLM_output = generate_completion(model, messages)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error generating completion: {e}\")\n",
    "\n",
    "print(LLM_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-presentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
