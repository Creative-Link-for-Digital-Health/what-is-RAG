{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Knowledge from an External File\n",
    "\n",
    "When we manually add external text to the system prompt, we are performing the retrieval step and augmenting the context that LLM receives. This gives LLM access to specific information that may not be in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "\n",
    "from openai import OpenAI\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "from api_utils import load_api_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API parameters and initialize client\n",
    "\n",
    "SECRETS_PATH = \".secrets.toml\"\n",
    "\n",
    "API_CALL_PARAMS = load_api_params(SECRETS_PATH)\n",
    "client = OpenAI(\n",
    "    base_url = API_CALL_PARAMS['API_URL'],\n",
    "    api_key = API_CALL_PARAMS['API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(model: str, messages: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"Generate LLM output\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def load_story_from_file(filename):\n",
    "    \"\"\"Load story text from a file\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE = load_story_from_file('heart_attack.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"Answer all user questions to the best of your ability. Use the following text for reference:\n",
    "\n",
    "{KNOWLEDGE}\n",
    "\n",
    "Use only the knowldege from the story for your answer. This is VERY important!\n",
    "\"\"\"\n",
    "\n",
    "print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"Can you please tell me what is a heart attack.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the story, in Wonderland, a \"Heart Attack\" has a different meaning than what you might be thinking. In this context, a Heart Attack refers to a war or an offensive launched by the Heart kingdom, led by the Queen of Hearts, against another kingdom, specifically the Spade kingdom.\n",
      "\n",
      "It's not a medical condition, but rather a term used to describe a passionate and impulsive attack, driven by emotions, as opposed to a strategic and calculated approach. The Queen of Hearts even uses it as a battle cry, summoning her card soldiers to launch a Heart Attack against the Queen of Spades.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"{SYSTEM_PROMPT}\"\"\"},\n",
    "    {\"role\": \"user\", \"content\":f\"\"\"{USER_PROMPT}\"\"\"}\n",
    "]\n",
    "try:\n",
    "    model = API_CALL_PARAMS['MODEL']\n",
    "    LLM_output = generate_completion(model, messages)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error generating completion: {e}\")\n",
    "\n",
    "print(LLM_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-presentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
